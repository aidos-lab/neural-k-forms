{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROTEINS\n",
    "\n",
    "In *message passing simplicial networks* they benchmark using some data sets from TUdatasets. Here we try the PROTEINS dataset. See \"Protein Function Prediction via Graph Kernels\", Bogwart et al., for details about the data set. \n",
    "\n",
    "There are two classes of graphs: *enzymes* and *not enzymes*\n",
    "\n",
    "The data set has node features in $\\{0,1 \\}^3$ . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo: \n",
    "- Check initialization of cochains: I think right now its random \n",
    "- Try different models,  maybe more convolutional layers or higher powers of L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import gudhi as gd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "  \n",
    "import cochainlearning as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/AIDS.zip\n",
      "Extracting tudata/TUDataset/AIDS/AIDS.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIDS(2000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = TUDataset(root='data/TUDataset', name='PROTEINS')\n",
    "dataset = TUDataset(root='tudata/TUDataset', name='AIDS')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: AIDS(2000):\n",
      "====================\n",
      "Number of graphs: 2000\n",
      "Number of features: 38\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 106], x=[47, 38], edge_attr=[106, 3], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 47\n",
      "Number of edges: 106\n",
      "Average node degree: 2.26\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate data into training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 800\n",
      "Number of test graphs: 1200\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "len_train_set = 800\n",
    "\n",
    "train_dataset = dataset[:len_train_set]\n",
    "test_dataset = dataset[len_train_set:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make clique complexess with the graphs\n",
    "clique complexes up to dimension 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2q_ql79j5_s6kq_b56rg9xdc0000gn/T/ipykernel_10436/58868366.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  node_features = torch.tensor(graph['x'])\n",
      "/var/folders/w2/2q_ql79j5_s6kq_b56rg9xdc0000gn/T/ipykernel_10436/58868366.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index =torch.tensor(data['edge_index']).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 2, 38])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def graph_to_chain(graph):\n",
    "    \"\"\" \n",
    "    A function for turning a graph into a chain\n",
    "    \"\"\"\n",
    "\n",
    "    # get node features\n",
    "    node_features = torch.tensor(graph['x'])\n",
    "\n",
    "    # get edges\n",
    "    edge_index =torch.tensor(data['edge_index']).T\n",
    "\n",
    "    # number of 1-simplices\n",
    "    r = edge_index.shape[0]\n",
    "\n",
    "    # embedding dimension\n",
    "    n = node_features.shape[1]\n",
    "\n",
    "    # sort the edge indices\n",
    "    edges = torch.tensor([np.sort([edge_index[i][0],edge_index[i][1]]) for i in range(len(edge_index))])\n",
    "\n",
    "    # initialize chain\n",
    "    chain = torch.zeros((r,2,n))\n",
    "\n",
    "    # turn edges into a 1-chain\n",
    "    for i in range(r):\n",
    "        chain[i,0,:] = node_features[edges[i][0]]\n",
    "        chain[i,1,:] = node_features[edges[i][1]]\n",
    "\n",
    "    return chain\n",
    "\n",
    "# example\n",
    "data = dataset[0]\n",
    "graph_to_chain(data).shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):  \n",
    "    \n",
    "    \"\"\"Define a simple model using convolutional layers and linear layers \n",
    "    to reduce the dim of the output \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, n, out, c = 5, m1 = 50, m2 = 30, m3 = 20, m4 = 10): ## check channel sizes\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.c = c\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        self.m3 = m3\n",
    "\n",
    "        # initialise vector field\n",
    "        self.vf = nn.Sequential(\n",
    "                    nn.Linear(n, m1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(m1, m2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(m2, n*c)\n",
    "                    )\n",
    "        \n",
    "        # initialise MLP classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(c, m3),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(m3, m4),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(m4, out)\n",
    "                    )\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## asses the dimensions are correct somewhere \n",
    "        \"Here the input is a chain, and the output is a vector of probabilities\"\n",
    "\n",
    "        # generate cochain data matrix\n",
    "        X = cl.gen_CDM(self.vf, x)\n",
    "\n",
    "        # orientation invariant square L2-norm readout function\n",
    "        X = torch.diag(X.T @ X)\n",
    "\n",
    "        # put output through classifier\n",
    "        output = self.classifier(X)\n",
    "\n",
    "        # softmax\n",
    "        sm = nn.functional.softmax(output)\n",
    "        \n",
    "        return sm\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2q_ql79j5_s6kq_b56rg9xdc0000gn/T/ipykernel_10436/2227267984.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sm = nn.functional.softmax(output)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4674, 0.5326], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = node_features.shape[1]\n",
    "out = dataset.num_classes\n",
    "\n",
    "basic_model = model(n = n, out = out)\n",
    "basic_model.forward(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(basic_model.parameters(), lr=1e-2)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset):\n",
    "    \n",
    "    basic_model.train()\n",
    "\n",
    "    for data in dataset:  # Iterate in batches over the training dataset.\n",
    "\n",
    "        chain = graph_to_chain(data)\n",
    "\n",
    "        out = basic_model.forward(chain)  # Perform a single forward pass.\n",
    "\n",
    "        # do a 1-hot encoding of data.y\n",
    "        y = torch.zeros(dataset.num_classes)\n",
    "        y[data.y] = 1\n",
    "        \n",
    "        print(out.shape)\n",
    "        print(y)\n",
    "\n",
    "        loss = criterion(out, y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "tensor([0., 1.])\n",
      "torch.Size([2])\n",
      "tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2q_ql79j5_s6kq_b56rg9xdc0000gn/T/ipykernel_10436/58868366.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  node_features = torch.tensor(graph['x'])\n",
      "/var/folders/w2/2q_ql79j5_s6kq_b56rg9xdc0000gn/T/ipykernel_10436/58868366.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index =torch.tensor(data['edge_index']).T\n",
      "/var/folders/w2/2q_ql79j5_s6kq_b56rg9xdc0000gn/T/ipykernel_10436/2227267984.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sm = nn.functional.softmax(output)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for dimension 0 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(dataset)\n",
      "Cell \u001b[0;32mIn[144], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m basic_model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dataset:  \u001b[39m# Iterate in batches over the training dataset.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     chain \u001b[39m=\u001b[39m graph_to_chain(data)\n\u001b[1;32m      9\u001b[0m     out \u001b[39m=\u001b[39m basic_model\u001b[39m.\u001b[39mforward(chain)  \u001b[39m# Perform a single forward pass.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39m# do a 1-hot encoding of data.y\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[82], line 27\u001b[0m, in \u001b[0;36mgraph_to_chain\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(r):\n\u001b[1;32m     26\u001b[0m     chain[i,\u001b[39m0\u001b[39m,:] \u001b[39m=\u001b[39m node_features[edges[i][\u001b[39m0\u001b[39m]]\n\u001b[0;32m---> 27\u001b[0m     chain[i,\u001b[39m1\u001b[39m,:] \u001b[39m=\u001b[39m node_features[edges[i][\u001b[39m1\u001b[39;49m]]\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m chain\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for dimension 0 with size 7"
     ]
    }
   ],
   "source": [
    "train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "batch_size = 300\n",
    "\n",
    "losses = torch.zeros((batch_size,epochs))\n",
    "\n",
    "for j in range(epochs):\n",
    "\n",
    "    # make a random choice of size batch_size\n",
    "    idx = np.random.choice(len(paths), size=batch_size, replace=False)\n",
    "\n",
    "    batch_paths = [paths[i] for i in idx]\n",
    "    batch_labels = labels[idx]\n",
    "\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "\n",
    "        p = batch_paths[i]\n",
    "        l = batch_labels[i]\n",
    "\n",
    "        p = path_to_chain(p)\n",
    "        \n",
    "        X = gen_CDM2(vf, p, d = 5)\n",
    "        X = torch.sum(X, dim = 0)\n",
    "\n",
    "        sm = torch.nn.functional.softmax(X)\n",
    "\n",
    "\n",
    "        loss = criterion(sm,l.float())\n",
    "\n",
    "        losses[i,j] = loss.detach()\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        # for some reason it works better doing the backprop/gradient step after each path\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # clear print statement from previous iteration\n",
    "    # clear_output(wait=True)\n",
    "    \n",
    "    print(\"Epoch = \", j, \"Loss = \", torch.sum(losses[:,j])/batch_size)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(5, 15))\n",
    "\n",
    "for i in range(3):\n",
    "    ax = axs[i]\n",
    "    plot_component_vf(vf, ax, comp = i, x_range=10, y_range=10)\n",
    "    ax.set_title('Component {}'.format(i+1))\n",
    "\n",
    "# add a title to the figure\n",
    "fig.suptitle('Final feature vector fields')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
