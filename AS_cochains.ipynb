{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to learn Alexander Spannier cochains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import coo_matrix,diags\n",
    "from scipy.sparse.linalg import inv\n",
    "import gudhi as gd\n",
    "import copy\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from itertools import permutations\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_diagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(np.sin(x+noise_y)+y_trans)\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "\n",
    "\n",
    "def generate_antidiagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(-np.sin(x+noise_y)+y_trans)\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def generate_circular_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        endpoint = np.random.randint(0,num_pts)\n",
    "        \n",
    "        sample_angles = list(np.sort(np.random.uniform(0,2*np.pi, num_pts)).astype('f'))\n",
    "        angles= sample_angles[endpoint:]+ sample_angles[:endpoint]\n",
    "        angles = np.array(angles)\n",
    "        \n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        #x_trans = np.random.randint(-5,5)\n",
    "        #y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        r = np.random.uniform(0.5, 2.5)\n",
    "\n",
    "        x_values = r*np.cos(angles)+noise_x\n",
    "        y_values = r*np.sin(angles)+noise_y\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "\n",
    "    return Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_parity(lst):\n",
    "    ''' Given a permutation of the digits 0..N in order as a list, \n",
    "    returns its parity (or sign): +1 for even parity; -1 for odd.\n",
    "    '''\n",
    "    parity = 1\n",
    "    for i in range(0,len(lst)-1):\n",
    "        if lst[i] != i:\n",
    "            parity *= -1\n",
    "            mn = min(range(i,len(lst)), key=lst.__getitem__)\n",
    "            lst[i],lst[mn] = lst[mn],lst[i]\n",
    "    return parity   \n",
    "\n",
    "#permute the entries of a simplex in torch tensor format\n",
    "def permute_simplex(simplex,perm):\n",
    "    \"\"\" permute the entries of a simplex in torch tensor format\"\"\"\n",
    "    permuted_simplex = torch.zeros(simplex.shape)\n",
    "    for i in range(simplex.shape[0]):\n",
    "        permuted_simplex[i] = simplex[perm[i]]\n",
    "    return permuted_simplex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([1, 4])\n",
      "tensor([[0.3696]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# initialise a AS cochain as an MLP\n",
    "# m = dimension of space the complex lives in \n",
    "# k = dimension of cochain \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 1)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp.shape)\n",
    "a = f(simp)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "tensor([-0.0964, -0.0475], grad_fn=<SelectBackward0>)\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "## we can also learn l different cochains \n",
    "l=2\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp)\n",
    "print(simp.shape)\n",
    "a = F(simp)[0]\n",
    "print(a)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0964, -0.0475], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cochain_eval(cochains,simplex):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    \n",
    "    l = cochains[-1].out_features\n",
    "    new_simplex = simplex.reshape(1,-1)\n",
    "    out = torch.zeros(l)\n",
    "    out = cochains(new_simplex)[0]\n",
    "\n",
    "    return out \n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "cochain_eval(F,simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 4.],\n",
      "        [1., 0.]])\n",
      "tensor([-0.0150,  0.0556], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# function to obtain the alternation of a cochain on a simplex\n",
    "\n",
    "def alternate_cochain(cochain,simplex):\n",
    "    \n",
    "    l = cochain[-1].out_features\n",
    "    s = simplex.shape[0]\n",
    "\n",
    "    alt = torch.zeros(l)\n",
    "    perm = permutations(range(simplex.shape[0]))\n",
    "\n",
    "    for i in list(perm): \n",
    "        simplex = permute_simplex(simplex,i)   \n",
    "        alt += perm_parity(list(i))*cochain_eval(cochain,simplex)\n",
    "    return alt/math.factorial(s)\n",
    "\n",
    "\n",
    "simp = torch.tensor([(1,0,),(0,4)]).float() \n",
    "print(permute_simplex(simp,[1,0]))\n",
    "\n",
    "l=2\n",
    "m = 2\n",
    "k = 1\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "a = alternate_cochain(F,simp)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celiahacker/opt/anaconda3/envs/celia/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0200],\n",
       "        [-0.0440],\n",
       "        [-0.0619],\n",
       "        [-0.0551],\n",
       "        [ 0.0000]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cochain_eval_path(cochains,path):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a simplicial complex\n",
    "     simplicial complex sc as array of simplices\"\"\"\n",
    "    \n",
    "    out = torch.zeros(path.shape[0],cochains[-1].out_features)\n",
    "\n",
    "    for i in range(path.shape[0]-1):\n",
    "        \n",
    "    \n",
    "        simplex = torch.tensor((path[i], path[i+1]))  # convert path[i] to a torch tensor efficiently later\n",
    "        #print(simplex)\n",
    "        out[i] = cochain_eval(cochains,simplex)\n",
    "    return out\n",
    "\n",
    "\n",
    "### example \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 1)\n",
    ")\n",
    "\n",
    "p0 = generate_diagonal_paths(num_paths=10,eps = 0.2, num_pts = 5)\n",
    "path = p0[0]\n",
    "\n",
    "cochain_eval_path(f,path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "\n",
    "num_paths = 100\n",
    "\n",
    "p0 = generate_diagonal_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "p1 = generate_antidiagonal_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "p2 = generate_circular_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "\n",
    "# join together p0, p1, p2\n",
    "paths = p0+p1+p2\n",
    "\n",
    "# generate labels\n",
    "labels = np.concatenate((np.zeros(num_paths),np.ones(num_paths),2*np.ones(num_paths))).astype('f')\n",
    "\n",
    "# perform a one hot encoding of the labels and transform to torch\n",
    "labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=3 # three classes so three outputs \n",
    "m = 2 # the paths live in R^2\n",
    "k = 1 # we deal with one simplices \n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 50), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, l)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celiahacker/opt/anaconda3/envs/celia/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3566666666666667\n",
      "1\n",
      "0.3466666666666667\n",
      "2\n",
      "0.35\n",
      "3\n",
      "0.3466666666666667\n",
      "4\n",
      "0.34\n",
      "5\n",
      "0.3433333333333333\n",
      "6\n",
      "0.34\n",
      "7\n",
      "0.33666666666666667\n",
      "8\n",
      "0.34\n",
      "9\n",
      "0.3466666666666667\n",
      "10\n",
      "0.3433333333333333\n",
      "11\n",
      "0.33\n",
      "12\n",
      "0.3333333333333333\n",
      "13\n",
      "0.3433333333333333\n",
      "14\n",
      "0.3433333333333333\n",
      "15\n",
      "0.3333333333333333\n",
      "16\n",
      "0.33\n",
      "17\n",
      "0.33666666666666667\n",
      "18\n",
      "0.32666666666666666\n",
      "19\n",
      "0.32666666666666666\n",
      "20\n",
      "0.33666666666666667\n",
      "21\n",
      "0.32666666666666666\n",
      "22\n",
      "0.33666666666666667\n",
      "23\n",
      "0.32666666666666666\n",
      "24\n",
      "0.3233333333333333\n",
      "25\n",
      "0.33\n",
      "26\n",
      "0.34\n",
      "27\n",
      "0.3233333333333333\n",
      "28\n",
      "0.33\n",
      "29\n",
      "0.33\n",
      "30\n",
      "0.3333333333333333\n",
      "31\n",
      "0.3233333333333333\n",
      "32\n",
      "0.34\n",
      "33\n",
      "0.3333333333333333\n",
      "34\n",
      "0.3233333333333333\n",
      "35\n",
      "0.3333333333333333\n",
      "36\n",
      "0.3333333333333333\n",
      "37\n",
      "0.33666666666666667\n",
      "38\n",
      "0.3333333333333333\n",
      "39\n",
      "0.33\n",
      "40\n",
      "0.32666666666666666\n",
      "41\n",
      "0.33\n",
      "42\n",
      "0.33\n",
      "43\n",
      "0.33666666666666667\n",
      "44\n",
      "0.33666666666666667\n",
      "45\n",
      "0.3333333333333333\n",
      "46\n",
      "0.33666666666666667\n",
      "47\n",
      "0.33666666666666667\n",
      "48\n",
      "0.33666666666666667\n",
      "49\n",
      "0.33666666666666667\n",
      "50\n",
      "0.34\n",
      "51\n",
      "0.3333333333333333\n",
      "52\n",
      "0.3566666666666667\n",
      "53\n",
      "0.33\n",
      "54\n",
      "0.34\n",
      "55\n",
      "0.33666666666666667\n",
      "56\n",
      "0.3333333333333333\n",
      "57\n",
      "0.3333333333333333\n",
      "58\n",
      "0.34\n",
      "59\n",
      "0.33666666666666667\n",
      "60\n",
      "0.34\n",
      "61\n",
      "0.34\n",
      "62\n",
      "0.33666666666666667\n",
      "63\n",
      "0.33666666666666667\n",
      "64\n",
      "0.34\n",
      "65\n",
      "0.34\n",
      "66\n",
      "0.3466666666666667\n",
      "67\n",
      "0.34\n",
      "68\n",
      "0.33666666666666667\n",
      "69\n",
      "0.3466666666666667\n",
      "70\n",
      "0.3433333333333333\n",
      "71\n",
      "0.33666666666666667\n",
      "72\n",
      "0.34\n",
      "73\n",
      "0.3333333333333333\n",
      "74\n",
      "0.33\n",
      "75\n",
      "0.32666666666666666\n",
      "76\n",
      "0.33666666666666667\n",
      "77\n",
      "0.33666666666666667\n",
      "78\n",
      "0.33\n",
      "79\n",
      "0.3333333333333333\n",
      "80\n",
      "0.3333333333333333\n",
      "81\n",
      "0.33666666666666667\n",
      "82\n",
      "0.3333333333333333\n",
      "83\n",
      "0.34\n",
      "84\n",
      "0.3333333333333333\n",
      "85\n",
      "0.32666666666666666\n",
      "86\n",
      "0.32666666666666666\n",
      "87\n",
      "0.33\n",
      "88\n",
      "0.3433333333333333\n",
      "89\n",
      "0.33\n",
      "90\n",
      "0.3333333333333333\n",
      "91\n",
      "0.32\n",
      "92\n",
      "0.33\n",
      "93\n",
      "0.3233333333333333\n",
      "94\n",
      "0.3333333333333333\n",
      "95\n",
      "0.3333333333333333\n",
      "96\n",
      "0.3233333333333333\n",
      "97\n",
      "0.3233333333333333\n",
      "98\n",
      "0.33\n",
      "99\n",
      "0.3233333333333333\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "batch_size = len(paths)\n",
    "\n",
    "orig_labels = np.concatenate((np.zeros(num_paths),np.ones(num_paths),2*np.ones(num_paths)))\n",
    "\n",
    "optim = torch.optim.SGD(F.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    print(e)\n",
    "\n",
    "    ## shuffle the data\n",
    "    idx = np.random.permutation(len(paths))\n",
    "    paths = [paths[i] for i in idx]\n",
    "    labels = labels[idx]\n",
    "    orig_labels = orig_labels[idx]\n",
    "\n",
    "    correct_pred = 0 \n",
    "\n",
    "    for i in range(len(paths)):\n",
    "\n",
    "        p = paths[i]\n",
    "        y = labels[i]\n",
    "        \n",
    "        X = cochain_eval_path(F,p)\n",
    "        X = torch.sum(X, dim = 0) \n",
    "        #print(X)\n",
    "\n",
    "        sm = torch.nn.functional.softmax(X) \n",
    "    \n",
    "        loss = criterion(sm,y.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # get the index of the max log-probability\n",
    "        pred = sm.argmax(keepdim=True).float()\n",
    "        #print(\"predictiton = \" ,pred)\n",
    "        #print(\"original label = \",orig_labels[i])\n",
    "\n",
    "        if pred == orig_labels[i]: ## \n",
    "          correct_pred += 1\n",
    "        \n",
    "        #print(\"y =\", y)\n",
    "        #print(\"sm =\", sm)\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "    print(correct_pred/len(paths))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graveyard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "tensor([0.0332], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Evaluate one cochain on a simplex \n",
    "\n",
    "def cochain_eval(cochain,simplex):\n",
    "\n",
    "    \"\"\" Evaluate a k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    simplex.reshape(1,-1)\n",
    "    simplex = simplex.reshape(1,-1)\n",
    "    out = torch.zeros(1)\n",
    "    out = cochain(simplex)[0]\n",
    "    print(out.shape)\n",
    "    return out \n",
    "\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "res = cochain_eval(f,simp)\n",
    "print(res.shape)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2sc(path):\n",
    "\n",
    "    sc = torch.zeros(len(path)-1, 4)\n",
    "    for i in range(len(path)):\n",
    "        sc[i,0] = path[i]\n",
    "        sc[i,1] = path[i+1]\n",
    "\n",
    "\n",
    "\n",
    "    return sc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
