{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to learn Alexander Spannier cochains "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Alexander-Spannier $k$-cochain on $\\mathbb{R}^m$ is a map $f:(\\mathbb{R}^m)^{k+1} \\longrightarrow \\mathbb{R}$. \n",
    "Given a simplex $k$-simplex $\\sigma = [v_0,\\cdots, v_k] \\subset \\R^m$, we can evaluate the cochain $f$ to get a value on $\\sigma$ by taking $f(\\sigma)= f(v_0,\\cdots,v_k)$. This gives a way of obtaining a cochain for a simplicial complex in $\\R^n$ by evaluating $f$ on all of its simplices. \n",
    "\n",
    "Then given a collection of simplicial complexes all embedded in $\\R^m$, they all get comparable or consistent features by evaluaing the same cochain  $f$ on each simplicial complex in the collection.\n",
    "\n",
    "\\textbf{Remark for later: } The set of Alexander-Spannier cochains and alternating Alexander-Spannie cochains are homotopy equivalent so at some point we might want to consider the set of alternating cochains (on simplicial complexes these correspond to the usual cochains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import coo_matrix,diags\n",
    "from scipy.sparse.linalg import inv\n",
    "import gudhi as gd\n",
    "import copy\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from itertools import permutations\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for generating paths data sets\n",
    "\n",
    "\n",
    "def generate_diagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(np.sin(x+noise_y)+y_trans)\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "\n",
    "\n",
    "def generate_antidiagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(-np.sin(x+noise_y)+y_trans)\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def generate_circular_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        endpoint = np.random.randint(0,num_pts)\n",
    "        \n",
    "        sample_angles = list(np.sort(np.random.uniform(0,2*np.pi, num_pts)).astype('f'))\n",
    "        angles= sample_angles[endpoint:]+ sample_angles[:endpoint]\n",
    "        angles = np.array(angles)\n",
    "        \n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        #x_trans = np.random.randint(-5,5)\n",
    "        #y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        r = np.random.uniform(0.5, 2.5)\n",
    "\n",
    "        x_values = r*np.cos(angles)+noise_x\n",
    "        y_values = r*np.sin(angles)+noise_y\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "\n",
    "    return Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Will be used later to obtain alternating AS cochains, but can be ignored for now\n",
    "\n",
    "def perm_parity(lst):\n",
    "    ''' Given a permutation of the digits 0..N in order as a list, \n",
    "    returns its parity (or sign): +1 for even parity; -1 for odd.\n",
    "    '''\n",
    "    parity = 1\n",
    "    for i in range(0,len(lst)-1):\n",
    "        if lst[i] != i:\n",
    "            parity *= -1\n",
    "            mn = min(range(i,len(lst)), key=lst.__getitem__)\n",
    "            lst[i],lst[mn] = lst[mn],lst[i]\n",
    "    return parity   \n",
    "\n",
    "#permute the entries of a simplex in torch tensor format\n",
    "def permute_simplex(simplex,perm):\n",
    "    \"\"\" permute the entries of a simplex in torch tensor format\"\"\"\n",
    "    permuted_simplex = torch.zeros(simplex.shape)\n",
    "    for i in range(simplex.shape[0]):\n",
    "        permuted_simplex[i] = simplex[perm[i]]\n",
    "    return permuted_simplex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([1, 4])\n",
      "tensor([[0.2600]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# initialise an AS cochain f as an MLP\n",
    "\n",
    "# m = dimension of space the complex lives in \n",
    "# k = dimension of cochain \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 1)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp.shape)\n",
    "a = f(simp) ## evaluate the cochain on the 1-simplex \n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "tensor([-0.1288, -0.0547], grad_fn=<SelectBackward0>)\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "## we can also learn l different cochains at once by using a nn.Sequential with l outputs\n",
    "\n",
    "l=2\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp)\n",
    "print(simp.shape)\n",
    "a = F(simp)[0]\n",
    "print(a)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 2]' is invalid for input of size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m\n\u001b[1;32m     24\u001b[0m F \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     25\u001b[0m     nn\u001b[39m.\u001b[39mLinear(m\u001b[39m*\u001b[39m(k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m10\u001b[39m),\n\u001b[1;32m     26\u001b[0m     nn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     nn\u001b[39m.\u001b[39mLinear(\u001b[39m200\u001b[39m, l)\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m simp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m),(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)])\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 33\u001b[0m a \u001b[39m=\u001b[39m cochain_eval(F,simp)\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mcochain_eval\u001b[0;34m(cochains, simplex)\u001b[0m\n\u001b[1;32m     11\u001b[0m new_simplex \u001b[39m=\u001b[39m simplex\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m#out = torch.zeros(l, requires_grad=True)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#print(out.is_leaf)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#out = cochains(new_simplex)[0]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#print(out.is_leaf)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mreshape(cochains(new_simplex)[\u001b[39m0\u001b[39;49m], (k\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m)))\n\u001b[1;32m     19\u001b[0m \u001b[39m#return cochains(new_simplex)[0] \u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m(torch\u001b[39m.\u001b[39mreshape(cochains(new_simplex)[\u001b[39m0\u001b[39m], (k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 2]' is invalid for input of size 2"
     ]
    }
   ],
   "source": [
    "## This is the main function I have issues with, it is supposed to evaluate a set of l k-cochains on a k-simplex but there is an issue when I try to actually learn\n",
    "## The issue is getting the right shape of output and making things differentiable..\n",
    "\n",
    "def cochain_eval(cochains,simplex):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    \n",
    "    l = cochains[-1].out_features\n",
    "    new_simplex = simplex.reshape(1,-1)\n",
    "    #out = torch.zeros(l, requires_grad=True)\n",
    "    #print(out.is_leaf)\n",
    "    #out = cochains(new_simplex)[0]\n",
    "    #print(out.is_leaf)\n",
    "    \n",
    "\n",
    "    print(torch.reshape(cochains(new_simplex)[0], (k+1,2)))\n",
    "    #return cochains(new_simplex)[0] \n",
    "    return(torch.reshape(cochains(new_simplex)[0], (k+1,2))) ## fix the k+1 and 1 to be more general \n",
    "\n",
    "\n",
    "l=2\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "a = cochain_eval(F,simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 4.],\n",
      "        [1., 0.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 2]' is invalid for input of size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     24\u001b[0m F \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     25\u001b[0m     nn\u001b[39m.\u001b[39mLinear(m\u001b[39m*\u001b[39m(k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m10\u001b[39m),\n\u001b[1;32m     26\u001b[0m     nn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     nn\u001b[39m.\u001b[39mLinear(\u001b[39m200\u001b[39m, l)\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m a \u001b[39m=\u001b[39m alternate_cochain(F,simp)\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(a)\n",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m, in \u001b[0;36malternate_cochain\u001b[0;34m(cochain, simplex)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(perm): \n\u001b[1;32m     12\u001b[0m     simplex \u001b[39m=\u001b[39m permute_simplex(simplex,i)   \n\u001b[0;32m---> 13\u001b[0m     alt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m perm_parity(\u001b[39mlist\u001b[39m(i))\u001b[39m*\u001b[39mcochain_eval(cochain,simplex)\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m alt\u001b[39m/\u001b[39mmath\u001b[39m.\u001b[39mfactorial(s)\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mcochain_eval\u001b[0;34m(cochains, simplex)\u001b[0m\n\u001b[1;32m     11\u001b[0m new_simplex \u001b[39m=\u001b[39m simplex\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m#out = torch.zeros(l, requires_grad=True)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#print(out.is_leaf)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#out = cochains(new_simplex)[0]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#print(out.is_leaf)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mreshape(cochains(new_simplex)[\u001b[39m0\u001b[39;49m], (k\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m)))\n\u001b[1;32m     19\u001b[0m \u001b[39m#return cochains(new_simplex)[0] \u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m(torch\u001b[39m.\u001b[39mreshape(cochains(new_simplex)[\u001b[39m0\u001b[39m], (k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 2]' is invalid for input of size 2"
     ]
    }
   ],
   "source": [
    "# function to obtain the alternation of a cochain on a simplex, we can take care of this once the issue above is fixed\n",
    "\n",
    "def alternate_cochain(cochain,simplex):\n",
    "    \n",
    "    l = cochain[-1].out_features\n",
    "    s = simplex.shape[0]\n",
    "\n",
    "    alt = torch.zeros(l)\n",
    "    perm = permutations(range(simplex.shape[0]))\n",
    "\n",
    "    for i in list(perm): \n",
    "        simplex = permute_simplex(simplex,i)   \n",
    "        alt += perm_parity(list(i))*cochain_eval(cochain,simplex)\n",
    "    return alt/math.factorial(s)\n",
    "\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,4)]).float() \n",
    "print(permute_simplex(simp,[1,0]))\n",
    "\n",
    "l=2\n",
    "m = 2\n",
    "k = 1\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "a = alternate_cochain(F,simp)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2q_ql79j5_s6kq_b56rg9xdc0000gn/T/ipykernel_3064/1095968076.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  simplex = torch.tensor((path[0], path[1]))  # convert path[i] to a torch tensor efficiently later\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 2]' is invalid for input of size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m path \u001b[39m=\u001b[39m p0[\u001b[39m0\u001b[39m]\n\u001b[1;32m     49\u001b[0m \u001b[39m#print(\"path = \", path )\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m output \u001b[39m=\u001b[39m cochain_eval_path(f,path)\n\u001b[1;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39moutput = \u001b[39m\u001b[39m\"\u001b[39m, output )\n\u001b[1;32m     52\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mcochain_eval_path\u001b[0;34m(cochains, path)\u001b[0m\n\u001b[1;32m      8\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(path\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],cochains[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mout_features, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m simplex \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor((path[\u001b[39m0\u001b[39m], path[\u001b[39m1\u001b[39m]))  \u001b[39m# convert path[i] to a torch tensor efficiently later\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m temp \u001b[39m=\u001b[39m cochain_eval(cochains,simplex)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(temp\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,path\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mcochain_eval\u001b[0;34m(cochains, simplex)\u001b[0m\n\u001b[1;32m     11\u001b[0m new_simplex \u001b[39m=\u001b[39m simplex\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m#out = torch.zeros(l, requires_grad=True)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#print(out.is_leaf)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#out = cochains(new_simplex)[0]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#print(out.is_leaf)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mreshape(cochains(new_simplex)[\u001b[39m0\u001b[39;49m], (k\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m)))\n\u001b[1;32m     19\u001b[0m \u001b[39m#return cochains(new_simplex)[0] \u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m(torch\u001b[39m.\u001b[39mreshape(cochains(new_simplex)[\u001b[39m0\u001b[39m], (k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 2]' is invalid for input of size 2"
     ]
    }
   ],
   "source": [
    "## A function to evaluate a set of l k-cochains on a path, this is the main function we will use to learn cochains on paths\n",
    "## making it work depends on the cochain_eval function above \n",
    "\n",
    "def cochain_eval_path(cochains,path):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a simplicial complex\n",
    "     simplicial complex sc as array of simplices\"\"\"\n",
    "    \n",
    "    out = torch.zeros(path.shape[0],cochains[-1].out_features, requires_grad=True)\n",
    "    simplex = torch.tensor((path[0], path[1]))  # convert path[i] to a torch tensor efficiently later\n",
    "    temp = cochain_eval(cochains,simplex)\n",
    "    print(temp.shape)\n",
    "\n",
    "    for i in range(1,path.shape[0]-1):\n",
    "\n",
    "        print(i)\n",
    "        simplex = torch.tensor((path[i], path[i+1]))  # convert path[i] to a torch tensor efficiently later\n",
    "        #print(simplex)\n",
    "        print(cochain_eval(cochains,simplex).shape)\n",
    "        \n",
    "\n",
    "        temp = torch.cat((temp, cochain_eval(cochains,simplex)),1)\n",
    "        print(temp.shape)\n",
    "\n",
    "        #print(out)\n",
    "\n",
    "        \n",
    "    #out.retain_grad()\n",
    "    #outout = torch.zeros(cochains[-1].out_features, requires_grad=True)\n",
    "    #outout = out \n",
    "    \n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "### example \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 2)\n",
    ")\n",
    "\n",
    "p0 = generate_diagonal_paths(num_paths=10,eps = 0.2, num_pts = 5)\n",
    "path = p0[0]\n",
    "#print(\"path = \", path )\n",
    "output = cochain_eval_path(f,path)\n",
    "print(\"output = \", output )\n",
    "print(output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning part\n",
    "\n",
    "Here we learn to classify three classes of paths in $\\R^2$, one class goes diagonally up to the right, one goes along the antiddiagonal down to the right and one is circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "\n",
    "num_paths = 100\n",
    "\n",
    "p0 = generate_diagonal_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "p1 = generate_antidiagonal_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "p2 = generate_circular_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "\n",
    "# join together p0, p1, p2\n",
    "paths = p0+p1+p2\n",
    "\n",
    "# generate labels\n",
    "labels = np.concatenate((np.zeros(num_paths),np.ones(num_paths),2*np.ones(num_paths))).astype('f')\n",
    "\n",
    "# perform a one hot encoding of the labels and transform to torch\n",
    "labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=3 # three classes so three outputs \n",
    "m = 2 # the paths live in R^2\n",
    "k = 1 # we deal with one simplices \n",
    "\n",
    "## We want to learn a set of k-cochains on the paths, we have three classes so we want to learn three k-cochains at once\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 50), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, l)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 2]' is invalid for input of size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m p \u001b[39m=\u001b[39m paths[i]\n\u001b[1;32m     27\u001b[0m y \u001b[39m=\u001b[39m labels[i]\n\u001b[0;32m---> 31\u001b[0m X \u001b[39m=\u001b[39m cochain_eval_path(F,p)\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(X)\n\u001b[1;32m     33\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(X, dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mcochain_eval_path\u001b[0;34m(cochains, path)\u001b[0m\n\u001b[1;32m      8\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(path\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],cochains[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mout_features, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m simplex \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor((path[\u001b[39m0\u001b[39m], path[\u001b[39m1\u001b[39m]))  \u001b[39m# convert path[i] to a torch tensor efficiently later\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m temp \u001b[39m=\u001b[39m cochain_eval(cochains,simplex)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(temp\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,path\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mcochain_eval\u001b[0;34m(cochains, simplex)\u001b[0m\n\u001b[1;32m     11\u001b[0m new_simplex \u001b[39m=\u001b[39m simplex\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m#out = torch.zeros(l, requires_grad=True)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#print(out.is_leaf)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#out = cochains(new_simplex)[0]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#print(out.is_leaf)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mreshape(cochains(new_simplex)[\u001b[39m0\u001b[39;49m], (k\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m)))\n\u001b[1;32m     19\u001b[0m \u001b[39m#return cochains(new_simplex)[0] \u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m(torch\u001b[39m.\u001b[39mreshape(cochains(new_simplex)[\u001b[39m0\u001b[39m], (k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 2]' is invalid for input of size 3"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "batch_size = len(paths)\n",
    "\n",
    "orig_labels = np.concatenate((np.zeros(num_paths),np.ones(num_paths),2*np.ones(num_paths)))\n",
    "\n",
    "optim = torch.optim.SGD(F.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    print(e)\n",
    "\n",
    "    ## shuffle the data\n",
    "    idx = np.random.permutation(len(paths))\n",
    "    paths = [paths[i] for i in idx]\n",
    "    labels = labels[idx]\n",
    "    orig_labels = orig_labels[idx]\n",
    "\n",
    "    correct_pred = 0 \n",
    "\n",
    "    for i in range(len(paths)):\n",
    "\n",
    "        p = paths[i]\n",
    "        y = labels[i]\n",
    "\n",
    "        \n",
    "\n",
    "        X = cochain_eval_path(F,p)\n",
    "        print(X)\n",
    "        X = torch.sum(X, dim = 0) \n",
    "        \n",
    "\n",
    "        print('bla')\n",
    "        sm = torch.nn.functional.softmax(X, dim =0) \n",
    "        print( sm)\n",
    "        print('y = ', y)\n",
    "\n",
    "        loss = criterion(sm,y.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        print('bla')\n",
    "        # get the index of the max log-probability\n",
    "        pred = sm.argmax(keepdim=True).float()\n",
    "        #print(\"predictiton = \" ,sm)\n",
    "        #print(\"original label = \",orig_labels[i])\n",
    "\n",
    "        if pred == orig_labels[i]: ## \n",
    "          correct_pred += 1\n",
    "        \n",
    "        #print(\"y =\", y)\n",
    "        #print(\"sm =\", sm)\n",
    "        #print(loss.grad)\n",
    "        optim.step()\n",
    "      \n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "    print(correct_pred/len(paths))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graveyard \n",
    "\n",
    "Some old functions I havent decided if I want to keep or no  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "tensor([0.0398, 0.0321], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Evaluate one cochain on a simplex \n",
    "\n",
    "def cochain_eval(cochain,simplex):\n",
    "\n",
    "    \"\"\" Evaluate a k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    simplex.reshape(1,-1)\n",
    "    simplex = simplex.reshape(1,-1)\n",
    "    out = torch.zeros(1)\n",
    "    out = cochain(simplex)[0]\n",
    "    print(out.shape)\n",
    "    return out \n",
    "\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "res = cochain_eval(f,simp)\n",
    "print(res.shape)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
