{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to learn Alexander Spannier cochains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import coo_matrix,diags\n",
    "from scipy.sparse.linalg import inv\n",
    "import gudhi as gd\n",
    "import copy\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from itertools import permutations\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(np.sin(x+noise_y)+y_trans)\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "\n",
    "\n",
    "def generate_antidiagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(-np.sin(x+noise_y)+y_trans)\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def generate_circular_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        endpoint = np.random.randint(0,num_pts)\n",
    "        \n",
    "        sample_angles = list(np.sort(np.random.uniform(0,2*np.pi, num_pts)).astype('f'))\n",
    "        angles= sample_angles[endpoint:]+ sample_angles[:endpoint]\n",
    "        angles = np.array(angles)\n",
    "        \n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        #x_trans = np.random.randint(-5,5)\n",
    "        #y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        r = np.random.uniform(0.5, 2.5)\n",
    "\n",
    "        x_values = r*np.cos(angles)+noise_x\n",
    "        y_values = r*np.sin(angles)+noise_y\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "\n",
    "    return Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_parity(lst):\n",
    "    ''' Given a permutation of the digits 0..N in order as a list, \n",
    "    returns its parity (or sign): +1 for even parity; -1 for odd.\n",
    "    '''\n",
    "    parity = 1\n",
    "    for i in range(0,len(lst)-1):\n",
    "        if lst[i] != i:\n",
    "            parity *= -1\n",
    "            mn = min(range(i,len(lst)), key=lst.__getitem__)\n",
    "            lst[i],lst[mn] = lst[mn],lst[i]\n",
    "    return parity   \n",
    "\n",
    "#permute the entries of a simplex in torch tensor format\n",
    "def permute_simplex(simplex,perm):\n",
    "    \"\"\" permute the entries of a simplex in torch tensor format\"\"\"\n",
    "    permuted_simplex = torch.zeros(simplex.shape)\n",
    "    for i in range(simplex.shape[0]):\n",
    "        permuted_simplex[i] = simplex[perm[i]]\n",
    "    return permuted_simplex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([1, 4])\n",
      "tensor([[0.0152]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# initialise a AS cochain as an MLP\n",
    "# m = dimension of space the complex lives in \n",
    "# k = dimension of cochain \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 1)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp.shape)\n",
    "a = f(simp)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "tensor([-0.0498,  0.1354], grad_fn=<SelectBackward0>)\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "## we can also learn l different cochains \n",
    "l=2\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp)\n",
    "print(simp.shape)\n",
    "a = F(simp)[0]\n",
    "print(a)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1956, -0.1005], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cochain_eval(cochains,simplex):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    \n",
    "    l = cochains[-1].out_features\n",
    "    new_simplex = simplex.reshape(1,-1)\n",
    "    out = torch.zeros(l)\n",
    "    out = cochains(new_simplex)[0]\n",
    "\n",
    "    return out \n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "cochain_eval(F,simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 4.],\n",
      "        [1., 0.]])\n",
      "tensor([-0.0317, -0.1362], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# function to obtain the alternation of a cochain on a simplex\n",
    "\n",
    "def alternate_cochain(cochain,simplex):\n",
    "    \n",
    "    l = cochain[-1].out_features\n",
    "    s = simplex.shape[0]\n",
    "\n",
    "    alt = torch.zeros(l)\n",
    "    perm = permutations(range(simplex.shape[0]))\n",
    "\n",
    "    for i in list(perm): \n",
    "        simplex = permute_simplex(simplex,i)   \n",
    "        alt += perm_parity(list(i))*cochain_eval(cochain,simplex)\n",
    "    return alt/math.factorial(s)\n",
    "\n",
    "\n",
    "simp = torch.tensor([(1,0,),(0,4)]).float() \n",
    "print(permute_simplex(simp,[1,0]))\n",
    "\n",
    "l=2\n",
    "m = 2\n",
    "k = 1\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "a = alternate_cochain(F,simp)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = generate_diagonal_paths(num_paths=10,eps = 0.2, num_pts = 5)\n",
    "path = p0[0]\n",
    "path[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1990],\n",
       "        [-0.1586],\n",
       "        [-0.1559],\n",
       "        [-0.1419],\n",
       "        [ 0.0000]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cochain_eval_path(cochains,path):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a simplicial complex\n",
    "     simplicial complex sc as array of simplices\"\"\"\n",
    "    \n",
    "    out = torch.zeros(path.shape[0],cochains[-1].out_features)\n",
    "\n",
    "    for i in range(path.shape[0]-1):\n",
    "        \n",
    "        simplex = torch.tensor((path[i], path[i+1]))\n",
    "        #print(simplex)\n",
    "        out[i] = cochain_eval(cochains,simplex)\n",
    "    return out\n",
    "\n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 1)\n",
    ")\n",
    "\n",
    "cochain_eval_path(f,path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "p0 = generate_diagonal_paths(num_paths=10,eps = 0.2, num_pts = 10)\n",
    "p1 = generate_antidiagonal_paths(num_paths=10,eps = 0.2, num_pts = 10)\n",
    "p2 = generate_circular_paths(num_paths=10,eps = 0.2, num_pts = 10)\n",
    "\n",
    "# join together p0, p1, p2\n",
    "paths = p0+p1+p2\n",
    "\n",
    "# generate labels\n",
    "labels = np.concatenate((np.zeros(10),np.ones(10),2*np.ones(10))).astype('f')\n",
    "\n",
    "# perform a one hot encoding of the labels and transform to torch\n",
    "labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=3 ## three classes so three outputs \n",
    "m = 2 ## the paths live in R^2\n",
    "k = 1 # we deal with one simplices \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([ 6.2697,  2.9502, -2.7518], grad_fn=<SumBackward1>)\n",
      "torch.Size([3])\n",
      "tensor([9.6498e-01, 3.4903e-02, 1.1656e-04], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-379c9be64b8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# and the target y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/celia/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/celia/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/celia/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "orig_labels = np.concatenate((np.zeros(10),np.ones(10),2*np.ones(10)))\n",
    "\n",
    "optim = torch.optim.SGD(F.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    print(e)\n",
    "\n",
    "    ## shuffle the data\n",
    "    idx = np.random.permutation(len(paths))\n",
    "    paths = [paths[i] for i in idx]\n",
    "    labels = labels[idx]\n",
    "    orig_labels = orig_labels[idx]\n",
    "\n",
    "    correct_pred = 0\n",
    "\n",
    "    for i in range(len(paths)):\n",
    "\n",
    "        p = paths[i]\n",
    "        y = labels[i]\n",
    "        \n",
    "        X = cochain_eval_path(F,p)\n",
    "\n",
    "        #print(X)\n",
    "        X = torch.sum(X, dim = 0) \n",
    "        \n",
    "        ## do we want to do this ? \n",
    "        print(X)\n",
    "        #print(\"*****\")\n",
    "\n",
    "        sm = torch.nn.functional.softmax(X, dim=0) \n",
    "\n",
    "\n",
    "        print(sm.shape)\n",
    "    \n",
    "        \n",
    "        print(sm)\n",
    "        #print(sm)\n",
    "\n",
    "        # and the target y\n",
    "        loss = criterion(sm,y.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # get the index of the max log-probability\n",
    "        #pred = sm.argmax(keepdim=True).float()\n",
    "\n",
    "        #print(labels[i])\n",
    "\n",
    "        #if pred == orig_labels[i]: ## \n",
    "         #   correct_pred += 1\n",
    "        \n",
    "        print(\"y =\", y)\n",
    "        print(\"sm =\", sm)\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "    #print(correct_pred/len(paths))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0201, -0.0215,  0.2926, -1.5066, -1.9511],\n",
      "        [ 0.3444, -0.8287, -0.5833, -0.1126, -1.2810],\n",
      "        [ 0.6459,  1.0271,  0.3656, -0.3480, -0.5376]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graveyard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "tensor([0.0332], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Evaluate one cochain on a simplex \n",
    "\n",
    "def cochain_eval(cochain,simplex):\n",
    "\n",
    "    \"\"\" Evaluate a k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    simplex.reshape(1,-1)\n",
    "    simplex = simplex.reshape(1,-1)\n",
    "    out = torch.zeros(1)\n",
    "    out = cochain(simplex)[0]\n",
    "    print(out.shape)\n",
    "    return out \n",
    "\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "res = cochain_eval(f,simp)\n",
    "print(res.shape)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2sc(path):\n",
    "\n",
    "    sc = torch.zeros(len(path)-1, 4)\n",
    "    for i in range(len(path)):\n",
    "        sc[i,0] = path[i]\n",
    "        sc[i,1] = path[i+1]\n",
    "\n",
    "\n",
    "\n",
    "    return sc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
