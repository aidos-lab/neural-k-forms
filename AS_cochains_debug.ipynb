{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to learn Alexander Spannier cochains "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Alexander-Spannier $k$-cochain on $\\mathbb{R}^m$ is a map $f:(\\mathbb{R}^m)^{k+1} \\longrightarrow \\mathbb{R}$. \n",
    "Given a simplex $k$-simplex $\\sigma = [v_0,\\cdots, v_k] \\subset \\R^m$, we can evaluate the cochain $f$ to get a value on $\\sigma$ by taking $f(\\sigma)= f(v_0,\\cdots,v_k)$. This gives a way of obtaining a cochain for a simplicial complex in $\\R^n$ by evaluating $f$ on all of its simplices. \n",
    "\n",
    "Then given a collection of simplicial complexes all embedded in $\\R^m$, they all get comparable or consistent features by evaluaing the same cochain  $f$ on each simplicial complex in the collection.\n",
    "\n",
    "\\textbf{Remark for later: } The set of Alexander-Spannier cochains and alternating Alexander-Spannie cochains are homotopy equivalent so at some point we might want to consider the set of alternating cochains (on simplicial complexes these correspond to the usual cochains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import coo_matrix,diags\n",
    "from scipy.sparse.linalg import inv\n",
    "import gudhi as gd\n",
    "import copy\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from itertools import permutations\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for generating paths data sets\n",
    "\n",
    "\n",
    "def generate_diagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(np.sin(x+noise_y)+y_trans)\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "\n",
    "\n",
    "def generate_antidiagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(-np.sin(x+noise_y)+y_trans)\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def generate_circular_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        endpoint = np.random.randint(0,num_pts)\n",
    "        \n",
    "        sample_angles = list(np.sort(np.random.uniform(0,2*np.pi, num_pts)).astype('f'))\n",
    "        angles= sample_angles[endpoint:]+ sample_angles[:endpoint]\n",
    "        angles = np.array(angles)\n",
    "        \n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        #x_trans = np.random.randint(-5,5)\n",
    "        #y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        r = np.random.uniform(0.5, 2.5)\n",
    "\n",
    "        x_values = r*np.cos(angles)+noise_x\n",
    "        y_values = r*np.sin(angles)+noise_y\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "\n",
    "    return Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([1, 4])\n",
      "tensor([[0.0661]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# initialise an AS cochain f as an MLP\n",
    "\n",
    "# m = dimension of space the complex lives in \n",
    "# k = dimension of cochain \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 1)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp.shape)\n",
    "a = f(simp) ## evaluate the cochain on the 1-simplex \n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "tensor([[-0.0627,  0.0017]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "## we can also learn l different cochains at once by using a nn.Sequential with l outputs\n",
    "\n",
    "l=2\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp)\n",
    "print(simp.shape)\n",
    "a = F(simp)\n",
    "print(a)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[-0.1285, -0.1476]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## This is the main function I have issues with, it is supposed to evaluate a set of l k-cochains on a k-simplex but there is an issue when I try to actually learn\n",
    "## The issue is getting the right shape of output and making things differentiable..\n",
    "\n",
    "def cochain_eval(cochains,simplex):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    \n",
    "    l = cochains[-1].out_features\n",
    "    \n",
    "    a = cochains(simplex.reshape(1,-1))\n",
    "    return(a)\n",
    "\n",
    "m = 2\n",
    "l=2\n",
    "k = 1\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, l)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "a = cochain_eval(F,simp)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  tensor([[-0.0223, -0.2099],\n",
      "        [-0.0048, -0.1947],\n",
      "        [ 0.0110, -0.1657],\n",
      "        [ 0.0375, -0.1091]], grad_fn=<CatBackward0>)\n",
      "torch.Size([4, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2q_ql79j5_s6kq_b56rg9xdc0000gn/T/ipykernel_8788/3051693023.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  simplex = torch.tensor((path[0], path[1]))  # convert path[i] to a torch tensor efficiently later\n"
     ]
    }
   ],
   "source": [
    "## A function to evaluate a set of l k-cochains on a path, this is the main function we will use to learn cochains on paths\n",
    "## making it work depends on the cochain_eval function above \n",
    "\n",
    "def cochain_eval_path(cochains,path):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a simplicial complex\n",
    "     simplicial complex sc as array of simplices\"\"\"\n",
    "    \n",
    "    simplex = torch.tensor((path[0], path[1]))  # convert path[i] to a torch tensor efficiently later\n",
    "    temp = cochain_eval(cochains,simplex)\n",
    "    temp.retain_grad()\n",
    "\n",
    "\n",
    "    for i in range(1,path.shape[0]-1):\n",
    "\n",
    "        simplex = torch.tensor((path[i], path[i+1]))  # convert path[i] to a torch tensor efficiently later\n",
    "        \n",
    "        temp = torch.cat((temp, cochain_eval(cochains,simplex)),0)\n",
    "        temp.retain_grad()\n",
    "       \n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "### example \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 2)\n",
    ")\n",
    "\n",
    "p0 = generate_diagonal_paths(num_paths=10,eps = 0.2, num_pts = 5)\n",
    "path = p0[0]\n",
    "#print(\"path = \", path )\n",
    "output = cochain_eval_path(f,path)\n",
    "print(\"output = \", output )\n",
    "print(output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning part\n",
    "\n",
    "Here we learn to classify three classes of paths in $\\R^2$, one class goes diagonally up to the right, one goes along the antiddiagonal down to the right and one is circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "\n",
    "num_paths = 100\n",
    "\n",
    "p0 = generate_diagonal_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "p1 = generate_antidiagonal_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "p2 = generate_circular_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "\n",
    "# join together p0, p1, p2\n",
    "paths = p0+p1+p2\n",
    "\n",
    "# generate labels\n",
    "labels = np.concatenate((np.zeros(num_paths),np.ones(num_paths),2*np.ones(num_paths))).astype('f')\n",
    "\n",
    "# perform a one hot encoding of the labels and transform to torch\n",
    "labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=3 # three classes so three outputs \n",
    "m = 2 # the paths live in R^2\n",
    "k = 1 # we deal with one simplices \n",
    "\n",
    "## We want to learn a set of k-cochains on the paths, we have three classes so we want to learn three k-cochains at once\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1),50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, l)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch : 0 Train Accuracy  0.27 Av. Loss:  tensor(0.9847)\n",
      "1\n",
      "Epoch : 1 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9795)\n",
      "2\n",
      "Epoch : 2 Train Accuracy  0.26666666666666666 Av. Loss:  tensor(0.9745)\n",
      "3\n",
      "Epoch : 3 Train Accuracy  0.26666666666666666 Av. Loss:  tensor(0.9700)\n",
      "4\n",
      "Epoch : 4 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9659)\n",
      "5\n",
      "Epoch : 5 Train Accuracy  0.27 Av. Loss:  tensor(0.9621)\n",
      "6\n",
      "Epoch : 6 Train Accuracy  0.27 Av. Loss:  tensor(0.9585)\n",
      "7\n",
      "Epoch : 7 Train Accuracy  0.27 Av. Loss:  tensor(0.9554)\n",
      "8\n",
      "Epoch : 8 Train Accuracy  0.27 Av. Loss:  tensor(0.9524)\n",
      "9\n",
      "Epoch : 9 Train Accuracy  0.26666666666666666 Av. Loss:  tensor(0.9495)\n",
      "10\n",
      "Epoch : 10 Train Accuracy  0.26666666666666666 Av. Loss:  tensor(0.9468)\n",
      "11\n",
      "Epoch : 11 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9445)\n",
      "12\n",
      "Epoch : 12 Train Accuracy  0.2633333333333333 Av. Loss:  tensor(0.9421)\n",
      "13\n",
      "Epoch : 13 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9400)\n",
      "14\n",
      "Epoch : 14 Train Accuracy  0.26666666666666666 Av. Loss:  tensor(0.9379)\n",
      "15\n",
      "Epoch : 15 Train Accuracy  0.2633333333333333 Av. Loss:  tensor(0.9360)\n",
      "16\n",
      "Epoch : 16 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9343)\n",
      "17\n",
      "Epoch : 17 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9325)\n",
      "18\n",
      "Epoch : 18 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9309)\n",
      "19\n",
      "Epoch : 19 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9292)\n",
      "20\n",
      "Epoch : 20 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9278)\n",
      "21\n",
      "Epoch : 21 Train Accuracy  0.28 Av. Loss:  tensor(0.9261)\n",
      "22\n",
      "Epoch : 22 Train Accuracy  0.28 Av. Loss:  tensor(0.9250)\n",
      "23\n",
      "Epoch : 23 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9235)\n",
      "24\n",
      "Epoch : 24 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9221)\n",
      "25\n",
      "Epoch : 25 Train Accuracy  0.27 Av. Loss:  tensor(0.9210)\n",
      "26\n",
      "Epoch : 26 Train Accuracy  0.27 Av. Loss:  tensor(0.9197)\n",
      "27\n",
      "Epoch : 27 Train Accuracy  0.27 Av. Loss:  tensor(0.9185)\n",
      "28\n",
      "Epoch : 28 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9174)\n",
      "29\n",
      "Epoch : 29 Train Accuracy  0.27 Av. Loss:  tensor(0.9162)\n",
      "30\n",
      "Epoch : 30 Train Accuracy  0.28 Av. Loss:  tensor(0.9152)\n",
      "31\n",
      "Epoch : 31 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9141)\n",
      "32\n",
      "Epoch : 32 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9131)\n",
      "33\n",
      "Epoch : 33 Train Accuracy  0.28 Av. Loss:  tensor(0.9122)\n",
      "34\n",
      "Epoch : 34 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9113)\n",
      "35\n",
      "Epoch : 35 Train Accuracy  0.28 Av. Loss:  tensor(0.9103)\n",
      "36\n",
      "Epoch : 36 Train Accuracy  0.28 Av. Loss:  tensor(0.9096)\n",
      "37\n",
      "Epoch : 37 Train Accuracy  0.27 Av. Loss:  tensor(0.9088)\n",
      "38\n",
      "Epoch : 38 Train Accuracy  0.27 Av. Loss:  tensor(0.9080)\n",
      "39\n",
      "Epoch : 39 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9072)\n",
      "40\n",
      "Epoch : 40 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9065)\n",
      "41\n",
      "Epoch : 41 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9057)\n",
      "42\n",
      "Epoch : 42 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9052)\n",
      "43\n",
      "Epoch : 43 Train Accuracy  0.27 Av. Loss:  tensor(0.9044)\n",
      "44\n",
      "Epoch : 44 Train Accuracy  0.27 Av. Loss:  tensor(0.9038)\n",
      "45\n",
      "Epoch : 45 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9033)\n",
      "46\n",
      "Epoch : 46 Train Accuracy  0.28 Av. Loss:  tensor(0.9027)\n",
      "47\n",
      "Epoch : 47 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9020)\n",
      "48\n",
      "Epoch : 48 Train Accuracy  0.2733333333333333 Av. Loss:  tensor(0.9015)\n",
      "49\n",
      "Epoch : 49 Train Accuracy  0.27666666666666667 Av. Loss:  tensor(0.9009)\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "batch_size = len(paths)\n",
    "\n",
    "orig_labels = np.concatenate((np.zeros(num_paths),np.ones(num_paths),2*np.ones(num_paths)))\n",
    "\n",
    "optim = torch.optim.SGD(F.parameters(), lr=1e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    print(e)\n",
    "\n",
    "    ## shuffle the data\n",
    "    idx = np.random.permutation(len(paths))\n",
    "    paths = [paths[i] for i in idx]\n",
    "    labels = labels[idx]\n",
    "    orig_labels = orig_labels[idx]\n",
    "\n",
    "    correct_pred = 0 \n",
    "\n",
    "    # initialise loss\n",
    "    l = 0\n",
    "\n",
    "    for i in range(len(paths)):\n",
    "\n",
    "        p = paths[i]\n",
    "        y = labels[i]\n",
    "\n",
    "        X = cochain_eval_path(F,p)\n",
    "        X = torch.sum(X, dim = 0)\n",
    "\n",
    "        \n",
    "        sm = torch.nn.functional.softmax(X, dim =0) \n",
    "\n",
    "        loss = criterion(sm,y.float())\n",
    "        loss.backward()\n",
    "\n",
    "        l += loss.detach()\n",
    "        \n",
    "        # get the index of the max log-probability\n",
    "        pred = sm.argmax(keepdim=True).float()\n",
    "        #print(\"predictiton = \" ,sm)\n",
    "        #print(\"original label = \",orig_labels[i])\n",
    "\n",
    "        if pred == orig_labels[i]: ## \n",
    "          correct_pred += 1\n",
    "        \n",
    "        #print(\"y =\", y)\n",
    "        #print(\"sm =\", sm)\n",
    "\n",
    "        #for name, param in F.named_parameters():\n",
    "        #  if param.grad is not None:\n",
    "        #      print(name, param.grad.sum())\n",
    "        #  else:\n",
    "        #      print(name, param.grad)\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    print(\"Epoch :\", e , \"Train Accuracy \", correct_pred/len(paths), \"Av. Loss: \", l/len(paths))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor(0.3255)\n",
      "0.bias tensor(-0.0222)\n",
      "2.weight tensor(-8.4955)\n",
      "2.bias tensor(-0.0255)\n",
      "4.weight tensor(-7.0196)\n",
      "4.bias tensor(-0.0730)\n",
      "6.weight tensor(-2.4088)\n",
      "6.bias tensor(-0.1100)\n",
      "8.weight tensor(-1.3672e-06)\n",
      "8.bias tensor(-3.1991e-07)\n"
     ]
    }
   ],
   "source": [
    "# print the gradient of the parameters in F\n",
    "for name, param in F.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(name, param.grad.sum())\n",
    "    else:\n",
    "        print(name, param.grad)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graveyard \n",
    "\n",
    "Some old functions I havent decided if I want to keep or no  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "tensor([0.0332], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Evaluate one cochain on a simplex \n",
    "\n",
    "def cochain_eval(cochain,simplex):\n",
    "\n",
    "    \"\"\" Evaluate a k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    simplex.reshape(1,-1)\n",
    "    simplex = simplex.reshape(1,-1)\n",
    "    out = torch.zeros(1)\n",
    "    out = cochain(simplex)[0]\n",
    "    print(out.shape)\n",
    "    return out \n",
    "\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "res = cochain_eval(f,simp)\n",
    "print(res.shape)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
