{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to learn Alexander Spannier cochains "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Alexander-Spannier $k$-cochain on $\\mathbb{R}^m$ is a map $f:(\\mathbb{R}^m)^{k+1} \\longrightarrow \\mathbb{R}$. \n",
    "Given a simplex $k$-simplex $\\sigma = [v_0,\\cdots, v_k] \\subset \\R^m$, we can evaluate the cochain $f$ to get a value on $\\sigma$ by taking $f(\\sigma)= f(v_0,\\cdots,v_k)$. This gives a way of obtaining a cochain for a simplicial complex in $\\R^n$ by evaluating $f$ on all of its simplices. \n",
    "\n",
    "Then given a collection of simplicial complexes all embedded in $\\R^m$, they all get comparable or consistent features by evaluaing the same cochain  $f$ on each simplicial complex in the collection.\n",
    "\n",
    "\\textbf{Remark for later: } The set of Alexander-Spannier cochains and alternating Alexander-Spannie cochains are homotopy equivalent so at some point we might want to consider the set of alternating cochains (on simplicial complexes these correspond to the usual cochains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import coo_matrix,diags\n",
    "from scipy.sparse.linalg import inv\n",
    "import gudhi as gd\n",
    "import copy\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from itertools import permutations\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for generating paths data sets\n",
    "\n",
    "\n",
    "def generate_diagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(np.sin(x+noise_y)+y_trans)\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "\n",
    "\n",
    "def generate_antidiagonal_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        x = np.sort(np.random.uniform(low=-1, high=1, size=num_pts).astype('f'))\n",
    "\n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        x_trans = np.random.randint(-5,5)\n",
    "        y_trans = np.random.randint(-5,5)\n",
    "        x_values = list(x+noise_x +x_trans)\n",
    "        y_values = list(-np.sin(x+noise_y)+y_trans)\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "        \n",
    "    return Paths\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def generate_circular_paths(num_paths=100,eps = 0.2, num_pts = 10):\n",
    "    \n",
    "    Paths = []\n",
    "    for i in range(num_paths): \n",
    "        endpoint = np.random.randint(0,num_pts)\n",
    "        \n",
    "        sample_angles = list(np.sort(np.random.uniform(0,2*np.pi, num_pts)).astype('f'))\n",
    "        angles= sample_angles[endpoint:]+ sample_angles[:endpoint]\n",
    "        angles = np.array(angles)\n",
    "        \n",
    "        noise_x= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "        noise_y= np.random.uniform(low= -eps, high = eps,  size = num_pts).astype('f')\n",
    "\n",
    "        #x_trans = np.random.randint(-5,5)\n",
    "        #y_trans = np.random.randint(-5,5)\n",
    "\n",
    "        r = np.random.uniform(0.5, 2.5)\n",
    "\n",
    "        x_values = r*np.cos(angles)+noise_x\n",
    "        y_values = r*np.sin(angles)+noise_y\n",
    "\n",
    "        path = np.stack((x_values,y_values))\n",
    "    \n",
    "        Paths.append(path.T)\n",
    "\n",
    "    return Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([1, 4])\n",
      "tensor([[-0.2522]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# initialise an AS cochain f as an MLP\n",
    "\n",
    "# m = dimension of space the complex lives in \n",
    "# k = dimension of cochain \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 1)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp.shape)\n",
    "a = f(simp) ## evaluate the cochain on the 1-simplex \n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1., 0., 0., 1.]])\n",
      "torch.Size([1, 4])\n",
      "tensor([[0.0995, 0.0342]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "## we can also learn l different cochains at once by using a nn.Sequential with l outputs\n",
    "\n",
    "l=2\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, l)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float() ## a 1-simplex with node values in R^2\n",
    "print(simp.shape)\n",
    "simp = simp.reshape(1,-1)\n",
    "print(simp)\n",
    "print(simp.shape)\n",
    "a = F(simp)\n",
    "print(a)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[ 0.0473, -0.0061]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## This is the main function I have issues with, it is supposed to evaluate a set of l k-cochains on a k-simplex but there is an issue when I try to actually learn\n",
    "## The issue is getting the right shape of output and making things differentiable..\n",
    "\n",
    "def cochain_eval(cochains,simplex):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    \n",
    "    l = cochains[-1].out_features\n",
    "    \n",
    "    a = cochains(simplex.reshape(1,-1))\n",
    "    a.retain_grad()\n",
    "    \n",
    "    return(a)\n",
    "\n",
    "m = 2\n",
    "l=2\n",
    "k = 1\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, l)\n",
    ")\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "a = cochain_eval(F,simp)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  tensor([[-0.1434, -0.0148],\n",
      "        [-0.1824, -0.0177],\n",
      "        [-0.1145, -0.0206],\n",
      "        [-0.1608,  0.0126]], grad_fn=<CatBackward0>)\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "## A function to evaluate a set of l k-cochains on a path, this is the main function we will use to learn cochains on paths\n",
    "## making it work depends on the cochain_eval function above \n",
    "\n",
    "def cochain_eval_path(cochains,path):\n",
    "    \"\"\" Evaluate a set of l k-cochains on a simplicial complex\n",
    "     simplicial complex sc as array of simplices\"\"\"\n",
    "    \n",
    "    simplex = torch.tensor((path[0], path[1]))  # convert path[i] to a torch tensor efficiently later\n",
    "    temp = cochain_eval(cochains,simplex)\n",
    "    temp.retain_grad()\n",
    "\n",
    "\n",
    "    for i in range(1,path.shape[0]-1):\n",
    "\n",
    "        simplex = torch.tensor((path[i], path[i+1]))  # convert path[i] to a torch tensor efficiently later\n",
    "        \n",
    "        temp = torch.cat((temp, cochain_eval(cochains,simplex)),0)\n",
    "        temp.retain_grad()\n",
    "       \n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "### example \n",
    "\n",
    "m =2\n",
    "k = 1\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 2)\n",
    ")\n",
    "\n",
    "p0 = generate_diagonal_paths(num_paths=10,eps = 0.2, num_pts = 5)\n",
    "path = p0[0]\n",
    "#print(\"path = \", path )\n",
    "output = cochain_eval_path(f,path)\n",
    "print(\"output = \", output )\n",
    "print(output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning part\n",
    "\n",
    "Here we learn to classify three classes of paths in $\\R^2$, one class goes diagonally up to the right, one goes along the antiddiagonal down to the right and one is circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "\n",
    "num_paths = 100\n",
    "\n",
    "p0 = generate_diagonal_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "p1 = generate_antidiagonal_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "p2 = generate_circular_paths(num_paths=num_paths,eps = 0.2, num_pts = 10)\n",
    "\n",
    "# join together p0, p1, p2\n",
    "paths = p0+p1+p2\n",
    "\n",
    "# generate labels\n",
    "labels = np.concatenate((np.zeros(num_paths),np.ones(num_paths),2*np.ones(num_paths))).astype('f')\n",
    "\n",
    "# perform a one hot encoding of the labels and transform to torch\n",
    "labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=3 # three classes so three outputs \n",
    "m = 2 # the paths live in R^2\n",
    "k = 1 # we deal with one simplices \n",
    "\n",
    "## We want to learn a set of k-cochains on the paths, we have three classes so we want to learn three k-cochains at once\n",
    "\n",
    "F = nn.Sequential(\n",
    "    nn.Linear(m*(k+1), 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, 200), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 50), ## random number \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, l)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celiahacker/opt/anaconda3/envs/celia/lib/python3.7/site-packages/ipykernel_launcher.py:51: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:485.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0.46\n",
      "1\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0.6\n",
      "2\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0.62\n",
      "3\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1bd847ee18ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/celia/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/celia/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "batch_size = len(paths)\n",
    "\n",
    "orig_labels = np.concatenate((np.zeros(num_paths),np.ones(num_paths),2*np.ones(num_paths)))\n",
    "\n",
    "optim = torch.optim.SGD(F.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    print(e)\n",
    "\n",
    "    ## shuffle the data\n",
    "    idx = np.random.permutation(len(paths))\n",
    "    paths = [paths[i] for i in idx]\n",
    "    labels = labels[idx]\n",
    "    orig_labels = orig_labels[idx]\n",
    "\n",
    "    correct_pred = 0 \n",
    "\n",
    "    for i in range(len(paths)):\n",
    "\n",
    "        p = paths[i]\n",
    "        y = labels[i]\n",
    "\n",
    "        X = cochain_eval_path(F,p)\n",
    "        X.retain_grad()\n",
    "        X = torch.sum(X, dim = 0) \n",
    "        X.retain_grad()\n",
    "\n",
    "        \n",
    "        sm = torch.nn.functional.softmax(X, dim =0) \n",
    "\n",
    "        loss = criterion(sm,y.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # get the index of the max log-probability\n",
    "        pred = sm.argmax(keepdim=True).float()\n",
    "        #print(\"predictiton = \" ,sm)\n",
    "        #print(\"original label = \",orig_labels[i])\n",
    "\n",
    "        if pred == orig_labels[i]: ## \n",
    "          correct_pred += 1\n",
    "        \n",
    "        #print(\"y =\", y)\n",
    "        #print(\"sm =\", sm)\n",
    "        print(loss.grad)\n",
    "        optim.step()\n",
    "      \n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "    print(correct_pred/len(paths))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graveyard \n",
    "\n",
    "Some old functions I havent decided if I want to keep or no  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "tensor([0.0332], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Evaluate one cochain on a simplex \n",
    "\n",
    "def cochain_eval(cochain,simplex):\n",
    "\n",
    "    \"\"\" Evaluate a k-cochains on a k-simplex \"\"\"\n",
    "    \n",
    "    # check size of simplex is compatible with cochain\n",
    "    assert simplex.shape == ((k+1),m), \"dimension of simplex and cochain does not match\"\n",
    "    simplex.reshape(1,-1)\n",
    "    simplex = simplex.reshape(1,-1)\n",
    "    out = torch.zeros(1)\n",
    "    out = cochain(simplex)[0]\n",
    "    print(out.shape)\n",
    "    return out \n",
    "\n",
    "\n",
    "simp = torch.tensor([(1,0),(0,1)]).float()\n",
    "res = cochain_eval(f,simp)\n",
    "print(res.shape)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
